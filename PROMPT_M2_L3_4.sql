-- ==========================================
-- PROMPT ENGINEERING MODULE 2 - LESSONS 3-6 (COMPLETE MODULE 2)
-- Core Techniques & Orchestration
-- ~1200 words each, compact HTML
-- Note: Lessons 1-2 already created in PROMPT_M2_L1.sql and PROMPT_M2_L2_3.sql
-- ==========================================

-- LESSON 3: Few-Shot Learning (ID: 48ec3816-6454-47fa-82c1-324ed414763a)
UPDATE lessons SET content = '<div class="lesson-content"><h2>Few-Shot Learning</h2><h3>Teaching AI Through Examples</h3><p>Few-shot learning is one of the most powerful and practical prompt engineering techniques. By providing a few examples, you can dramatically improve AI performance without any training or fine-tuning. This lesson teaches you how to use examples effectively.</p><h3>What Is Few-Shot Learning?</h3><p>Few-shot learning means providing examples in your prompt to demonstrate the pattern you want AI to follow. Zero-shot: No examples, just instructions. One-shot: One example provided. Few-shot: Multiple examples (typically 2-5). Many-shot: Many examples (5+, limited by context window).</p><h3>Why Examples Work</h3><p>Examples are powerful because they show rather than tell the pattern, reduce ambiguity about requirements, demonstrate format and style clearly, activate relevant patterns in AI training data, and work across different AI models consistently.</p><h3>Basic Few-Shot Pattern</h3><p>The standard structure is: Task description, Example 1 with input and output, Example 2 with input and output, Example 3 with input and output, then your actual input. AI learns the pattern from examples and applies it to your input.</p><h3>When to Use Few-Shot Learning</h3><p>Few-shot learning is especially effective for: Format specification (showing exact output structure), Style consistency (demonstrating tone and voice), Classification tasks (showing category examples), Transformation tasks (input to output mappings), Edge cases (handling special situations), Domain-specific tasks (industry terminology and patterns).</p><h3>Crafting Effective Examples</h3><p>Good examples are representative of the task, diverse enough to show the pattern, clear and unambiguous, realistic and practical, and cover edge cases when relevant. Bad examples are too similar to each other, overly simple or complex, inconsistent in format, unrealistic or contrived, and missing important variations.</p><h3>Example Quality Over Quantity</h3><p>More examples are not always better. Optimal number is typically 2-5 examples for most tasks. Too few examples (1) may not establish pattern clearly. Too many examples (10+) waste context window and may confuse. Quality matters more than quantity.</p><h3>Few-Shot for Different Tasks</h3><p>For classification: Show examples of each category with clear labels. For generation: Demonstrate desired format, length, and style. For transformation: Show input-output pairs clearly. For extraction: Highlight what to extract and how to format it. For reasoning: Show step-by-step thinking process.</p><h3>Structuring Few-Shot Prompts</h3><p>Clear structure helps AI learn: Use consistent formatting for all examples. Separate examples clearly (numbering, dividers). Label inputs and outputs explicitly. Maintain same structure for your actual query. Use clear delimiters between sections.</p><h3>Few-Shot Best Practices</h3><p>Start with 2-3 examples and add more if needed. Make examples diverse but representative. Use realistic, practical examples. Keep format consistent across examples. Include edge cases when relevant. Test with different example sets. Document what works for reuse.</p><h3>Common Few-Shot Mistakes</h3><p>Mistake 1: Examples too similar - they do not show pattern range. Solution: Vary examples meaningfully. Mistake 2: Inconsistent formatting - AI gets confused. Solution: Use identical structure. Mistake 3: Unrealistic examples - AI learns wrong patterns. Solution: Use real-world examples. Mistake 4: Too many examples - wastes context. Solution: Find optimal number through testing.</p><h3>Advanced Few-Shot Techniques</h3><p>Dynamic example selection: Choose examples based on input similarity. Contrastive examples: Show what to do AND what not to do. Hierarchical examples: Start simple, build complexity. Meta-examples: Examples of how to create examples. Chain-of-thought examples: Show reasoning process in examples.</p><h3>Few-Shot vs Fine-Tuning</h3><p>Few-shot learning: No training required, works immediately, flexible and adaptable, limited by context window, examples needed each time. Fine-tuning: Requires training data and process, takes time and resources, specialized for specific task, no context limit, no examples needed after training. Few-shot is better for: Quick iteration, varied tasks, limited data, experimentation. Fine-tuning is better for: Production systems, high volume, specialized domains, consistent tasks.</p><h3>Measuring Few-Shot Effectiveness</h3><p>Test with and without examples to compare accuracy. Try different numbers of examples to find optimal count. Vary example selection to test robustness. Measure consistency across multiple runs. Track which example patterns work best.</p><h3>Few-Shot for Complex Tasks</h3><p>For complex tasks, break into subtasks with examples for each step, show complete workflow in examples, include intermediate steps, demonstrate error handling, and provide success criteria in examples.</p><h3>Combining Few-Shot with Other Techniques</h3><p>Few-shot plus chain-of-thought: Examples show reasoning steps. Few-shot plus role assignment: Examples demonstrate expert behavior. Few-shot plus constraints: Examples respect all rules. Few-shot plus output formatting: Examples show exact format.</p><h3>Building Example Libraries</h3><p>Create reusable example sets for common tasks. Document which examples work best. Version control your example sets. Share successful patterns with team. Continuously refine based on results.</p><h3>Key Takeaways</h3><ul><li>Few-shot learning teaches AI through examples without training</li><li>Optimal number is typically 2-5 examples</li><li>Examples should be diverse, realistic, and consistently formatted</li><li>Quality matters more than quantity</li><li>Effective for format specification, classification, transformation, extraction</li><li>Structure examples clearly with labels and delimiters</li><li>Test different example sets to find what works best</li><li>Combine with other techniques for complex tasks</li></ul><p>In the next lesson, we will explore Core Prompt Components and how to structure comprehensive prompts.</p></div>'
WHERE id = '48ec3816-6454-47fa-82c1-324ed414763a';

-- LESSON 4: Core Prompt Components (ID: 9c6b9ec3-cfcf-44b1-8f5b-2de661b1299c)
UPDATE lessons SET content = '<div class="lesson-content"><h2>Core Prompt Components</h2><h3>Building Blocks of Effective Prompts</h3><p>Every effective prompt is built from core components. Understanding these building blocks helps you construct better prompts systematically. This lesson breaks down the essential components and how to use them.</p><h3>The Six Core Components</h3><p>1. Role/Persona: Who the AI should be. 2. Context: Background information and situation. 3. Task: What you want AI to do. 4. Format: How to structure the output. 5. Constraints: Rules and limitations. 6. Examples: Demonstrations of desired output.</p><h3>Component 1: Role and Persona</h3><p>Defining who AI should be shapes its responses. Examples: You are an expert software architect. You are a friendly customer support agent. You are a technical writer for developers. You are a data scientist specializing in healthcare. Benefits: Sets appropriate knowledge level, establishes tone and style, activates relevant training patterns, provides consistent perspective.</p><h3>Component 2: Context</h3><p>Context provides the situation and background. Include: Domain or industry, audience information, relevant background, current situation, goals and objectives, constraints and requirements. Example: We are a B2B SaaS company selling to enterprise clients. Our product is project management software. We are launching a new feature next month.</p><h3>Component 3: Task</h3><p>The task is what you want AI to do. Be specific: Use action verbs (write, analyze, create, extract). Define scope clearly. Specify deliverables. Set success criteria. Include any steps or process. Example: Write a product announcement email for our new feature, focusing on benefits for project managers, to be sent to our existing customer base.</p><h3>Component 4: Format</h3><p>Format specifies output structure. Common formats: Length (word count, character limit). Structure (sections, headings). Style (bullet points, paragraphs, tables). Data format (JSON, CSV, markdown). Template (specific layout). Example: Provide a 500-word email with: Subject line, opening paragraph, 3 bullet points of benefits, call to action, closing.</p><h3>Component 5: Constraints</h3><p>Constraints are rules and limitations. Types: What to avoid (no jargon, no technical terms). What to include (must mention X). Tone restrictions (professional, not casual). Content limits (under 500 words). Style requirements (active voice only). Example: Do not use technical jargon. Keep sentences under 20 words. Use active voice. Avoid marketing hype.</p><h3>Component 6: Examples</h3><p>Examples demonstrate desired output. Include when: Format is complex or specific. Style needs to be matched. Pattern is not obvious. Quality bar needs demonstration. Edge cases exist. Example: Here is an example of our preferred style: [example]. Now create one for [your topic].</p><h3>Putting Components Together</h3><p>A complete prompt structure: Role: You are [persona]. Context: [Background and situation]. Task: [What to do]. Format: [How to structure output]. Constraints: [Rules and limitations]. Examples: [Demonstrations]. Your input: [Actual query].</p><h3>Component Priority</h3><p>Not all components needed for every prompt. Minimum viable prompt: Task (always required). Enhanced prompt: Task plus Format. Strong prompt: Task, Format, Context. Comprehensive prompt: All six components. Use judgment based on task complexity.</p><h3>Component Ordering</h3><p>Recommended order: 1. Role (sets the stage). 2. Context (provides background). 3. Task (defines objective). 4. Format (specifies structure). 5. Constraints (sets boundaries). 6. Examples (demonstrates pattern). This order builds understanding progressively.</p><h3>Adapting Components for Different Tasks</h3><p>For creative tasks: Emphasize role and examples, lighter on constraints. For analytical tasks: Emphasize context and task, detailed format. For technical tasks: Emphasize constraints and format, precise task. For conversational tasks: Emphasize role and context, flexible format.</p><h3>Component Templates</h3><p>Create reusable templates for common scenarios. Template for content creation: Role: Content creator. Context: Audience and purpose. Task: Type of content. Format: Structure and length. Constraints: Brand guidelines. Examples: Previous content. Template for analysis: Role: Analyst or expert. Context: Data and situation. Task: Analysis type. Format: Report structure. Constraints: Methodology. Examples: Sample analysis.</p><h3>Testing Component Effectiveness</h3><p>Test by removing components one at a time to see impact. Add components progressively to find minimum needed. Compare outputs with different component combinations. Measure which components improve quality most. Document effective component patterns.</p><h3>Common Component Mistakes</h3><p>Mistake 1: Conflicting components - role and constraints contradict. Solution: Ensure alignment. Mistake 2: Missing critical component - no format specified. Solution: Include all relevant components. Mistake 3: Overly detailed components - too much information. Solution: Be concise and relevant. Mistake 4: Vague components - unclear task or format. Solution: Be specific and explicit.</p><h3>Advanced Component Techniques</h3><p>Nested components: Sub-tasks with own components. Conditional components: If X then Y constraints. Progressive components: Build complexity over conversation. Meta-components: Instructions about instructions. Dynamic components: Adapt based on input.</p><h3>Component Optimization</h3><p>Start comprehensive then simplify. Remove components that do not improve output. Refine wording for clarity. Test variations systematically. Document what works. Build component library for reuse.</p><h3>Key Takeaways</h3><ul><li>Six core components: role, context, task, format, constraints, examples</li><li>Not all components needed for every prompt</li><li>Recommended order: role, context, task, format, constraints, examples</li><li>Adapt component emphasis based on task type</li><li>Create reusable component templates</li><li>Test to find minimum effective components</li><li>Ensure components align and do not conflict</li><li>Be specific and explicit in each component</li></ul><p>In the next lesson, we will explore Context Layering for managing complex information.</p></div>'
WHERE id = '9c6b9ec3-cfcf-44b1-8f5b-2de661b1299c';

-- MODULE 2 LESSONS 3-4 COMPLETE
-- Continuing with lessons 5-6 in next file: PROMPT_M2_L5_6.sql
