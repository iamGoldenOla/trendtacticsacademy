-- UPDATE LESSONS 2-9: FOUNDATIONS & CORE WORKFLOW
-- Run this in Supabase SQL Editor

-- LESSON 2: From Writing Code to Directing Systems
UPDATE lessons SET
    content = '<h2>The Soloist vs. The Conductor</h2><p>A Soloist focuses on one line at a time. A Conductor listens to the whole symphony. Modern developers must think in systems, not individual files.</p><h3>Why File-by-File is Obsolete</h3><p>Thinking about a single file ignores the side effects on the rest of the app. AI agents like Cursor Composer allow you to edit 20 files at once. You must visualize the graph of your application, not just the current file.</p><h3>System Thinking in Practice</h3><p>Ask: ''If I change the User Schema, what breaks?'' The AI might miss this cascading impact. You must not. You provide the ''Global Context'' that the AI fundamentally lacks—the understanding of your business logic, your user flows, and your technical debt.</p><h3>The Architecture Layer</h3><p>Your role is to maintain the mental model of the entire system. This includes:</p><ul><li><strong>Data Flow</strong>: How information moves from database to UI</li><li><strong>Dependencies</strong>: Which components rely on others</li><li><strong>Side Effects</strong>: What changes when one thing changes</li><li><strong>Invariants</strong>: What must always remain true</li></ul><h3>Key Decisions Over Keystrokes</h3><p>Decisions > Keystrokes. You are responsible for the architecture. AI is a powerful engine, but it needs a steering wheel. The value you provide is knowing WHERE to go, not how fast you can type the directions.</p><h3>Common System-Level Mistakes</h3><ul><li>Letting AI refactor without understanding dependencies</li><li>Ignoring database migration implications</li><li>Not considering performance at scale</li><li>Forgetting about authentication/authorization</li></ul>',
    summary = 'Modern developers must shift from file-by-file thinking to system-level orchestration, maintaining the global context that AI cannot understand on its own.',
    case_studies = '[{"title": "The Refactor That Broke Production", "scenario": "A developer used AI to refactor a utility function without considering its 47 dependents across the codebase.", "analysis": "The AI perfectly refactored the function - cleaner code, better naming - but it did not understand the implicit contracts other modules depended on.", "outcome": "Three hours of debugging taught the team to always map dependencies before AI-assisted refactoring. They now use Cursor''s @codebase feature to see all file references."}]'::jsonb,
    key_takeaways = '["Think in systems, not files - every change has ripple effects.", "Maintain the global context AI cannot see - you are the architect.", "Decisions matter more than keystrokes - know WHERE to go."]'::jsonb,
    quizzes = '[{"question": "What is the difference between a Soloist and a Conductor mindset?", "options": ["Speed of coding", "Focus on individual lines vs whole system", "Programming language preference", "Team size"], "correctAnswer": 1, "explanation": "A Conductor thinks about the whole system and its interactions, not just individual lines of code."}, {"question": "Why is file-by-file thinking obsolete?", "options": ["Files are too small", "Changes affect the entire system", "AI cannot read files", "Computers are faster"], "correctAnswer": 1, "explanation": "Changes in one file often cascade through the entire system."}, {"question": "What provides the Global Context?", "options": ["The AI model", "The database", "The human developer", "The framework"], "correctAnswer": 2, "explanation": "You provide the context about business logic and system architecture that AI cannot infer."}, {"question": "What should you ask before making changes?", "options": ["Is this fast?", "What breaks if I change this?", "Is this pretty?", "Is this commented?"], "correctAnswer": 1, "explanation": "Understanding the impact of changes is crucial for system integrity."}, {"question": "What matters more than typing speed?", "options": ["Mouse speed", "Architectural decisions", "Comment quality", "Variable naming"], "correctAnswer": 1, "explanation": "The decisions about WHERE to go matter more than how fast you type."}]'::jsonb,
    videos = '[{"title": "System Design for AI-Assisted Development", "url": "https://www.youtube.com/embed/Sal7cz3T40M", "why_this_video": "Shows how to think about systems when using AI tools for development."}]'::jsonb,
    playground = '{"objective": "Practice system-level thinking by mapping dependencies before refactoring", "environment": "cursor", "starter_prompt": "Show me all files that import or use the function formatDate", "guided_steps": ["Identify a core utility or component in your project", "Use @codebase to find all references", "Map the dependency graph on paper or a tool", "Plan a refactor that touches multiple files", "Predict the impact before executing"], "advanced_challenge": "Refactor a shared utility function without breaking any of its 10+ consumers", "failure_mode_experiment": "Make a breaking change to a central component and observe the cascade failures", "real_world_simulation": "Plan a database schema migration - identify every file that would need changes"}'::jsonb,
    duration = 15
WHERE title = 'From Writing Code to Directing Systems';

-- LESSON 3: Intent Is the New Programming Language
UPDATE lessons SET
    content = '<h2>Language as Logic</h2><p>In 2026, English (or any natural language) is the highest-level programming language. The compiler is the LLM. The syntax is your clarity of thought.</p><h3>Vague vs. Constrained Prompts</h3><p><strong>Bad:</strong> ''Make a landing page.'' (Ambiguous, leads to hallucinations and random choices)</p><p><strong>Good:</strong> ''Create a Next.js landing page with: 1) A black H1 using Inter font 600 weight, 2) A sticky navbar with logo left and 3 links right, 3) A contact form that sends to contact@example.com using Resend.'' (Constrained, Specific, Actionable)</p><h3>The Specificity Spectrum</h3><ul><li><strong>Too Vague</strong>: AI makes random choices, high variance</li><li><strong>Just Right</strong>: Clear constraints, predictable output</li><li><strong>Too Specific</strong>: Might as well write the code yourself</li></ul><h3>Translating Business to Technical</h3><p>Your skill is translating ''We need more sales'' (Business) into ''Add a popup modal with a 10% discount code that appears on exit intent, tracked with Posthog'' (Technical). This translation is the core value of a Vibe Coder.</p><h3>The Prompting Mindset</h3><p>Ambiguity = Bugs. Specific Constraints = Correct Code. Prompting is just specifying requirements clearly. If you can''t specify it, you can''t prompt it. If you can''t prompt it, AI can''t build it.</p><h3>Prompt Patterns That Work</h3><ol><li><strong>Task + Context + Constraints + Format</strong></li><li><strong>Example-Driven</strong>: ''Like this, but with X change''</li><li><strong>Negative Constraints</strong>: ''Do NOT use class components''</li><li><strong>Step-by-Step</strong>: ''First do X, then do Y, finally Z''</li></ol>',
    summary = 'Natural language has become the highest-level programming language. Success depends on precise, constrained prompts that leave no room for ambiguity.',
    case_studies = '[{"title": "The $50,000 Prompt", "scenario": "A startup was spending $50K on developers to build a feature. The founder decided to try Vibe Coding first.", "analysis": "The original vague prompt (make a dashboard) required 40 iterations over 2 weeks. After prompt engineering training, a precise 5-sentence prompt worked in 2 tries.", "outcome": "Investing 2 hours learning prompt engineering saved weeks of development and $50K in contractor costs. The founder now teaches a prompt engineering workshop."}]'::jsonb,
    key_takeaways = '["Ambiguity = Bugs - vague prompts produce unpredictable results.", "Constraints create correct code - be specific about what you want AND do not want.", "Prompting IS requirements specification - the skills are the same."]'::jsonb,
    quizzes = '[{"question": "What is the compiler in Vibe Coding?", "options": ["GCC", "The LLM", "JavaScript V8", "The browser"], "correctAnswer": 1, "explanation": "The LLM translates natural language prompts into executable code."}, {"question": "What makes a prompt good?", "options": ["Length", "Constraints and specificity", "Politeness", "Technical jargon"], "correctAnswer": 1, "explanation": "Specific constraints produce predictable, correct results."}, {"question": "What does ambiguity cause in AI output?", "options": ["Faster output", "Bugs and hallucinations", "Better creativity", "Cleaner code"], "correctAnswer": 1, "explanation": "Ambiguity leads to unpredictable AI behavior and incorrect assumptions."}, {"question": "What skill translates business needs to prompts?", "options": ["Sales", "Prompt engineering", "Design", "Marketing"], "correctAnswer": 1, "explanation": "Prompt engineering bridges business requirements and technical implementation."}, {"question": "Prompting is essentially:", "options": ["Marketing copy", "Requirements specification", "Documentation", "Testing"], "correctAnswer": 1, "explanation": "Clear prompts are clear requirements - the skills overlap completely."}]'::jsonb,
    videos = '[{"title": "The Art of Prompting for Code", "url": "https://www.youtube.com/embed/sFkS-XJb6jo", "why_this_video": "Practical techniques for writing effective code generation prompts."}]'::jsonb,
    playground = '{"objective": "Transform vague prompts into precise specifications and observe the difference", "environment": "cursor", "starter_prompt": "Make a website", "guided_steps": ["Copy the vague starter prompt to Cursor", "Observe the output - note randomness", "Rewrite with 5 specific constraints (framework, colors, features)", "Compare the two outputs", "Document which constraints mattered most"], "advanced_challenge": "Write a prompt that produces correct code on the FIRST try - no iterations", "failure_mode_experiment": "Find the most ambiguous valid prompt and document all the random choices AI makes", "real_world_simulation": "Take an actual client email request and translate it into a precise technical prompt"}'::jsonb,
    duration = 15
WHERE title = 'Intent Is the New Programming Language';

-- LESSON 4: How AI Thinks (and Why It Breaks)
UPDATE lessons SET
    content = '<h2>Prediction, Not Reason</h2><p>LLMs are prediction engines, not reasoning engines. They predict the most likely next token based on training data. This is not ''thinking'' in the human sense—it''s pattern matching at an enormous scale.</p><h3>The Autocomplete Model</h3><p>Imagine the world''s most sophisticated autocomplete. That''s what an LLM is. When you type ''def calculate_total('', it predicts what usually comes next based on millions of examples. This is powerful but fundamentally different from understanding.</p><h3>Why This Matters for Vibe Coding</h3><ul><li><strong>Hallucinations</strong>: AI ''confidently'' invents things that don''t exist (fake APIs, wrong syntax)</li><li><strong>Context Blindness</strong>: AI doesn''t truly understand YOUR specific codebase</li><li><strong>Pattern Repetition</strong>: AI favors common patterns, even when they''re wrong for your case</li><li><strong>No Memory</strong>: Each conversation starts fresh (mostly)</li></ul><h3>The Probability Problem</h3><p>AI picks the ''most likely'' output, not the ''correct'' output. If 90% of the training data did something one way, it will suggest that way—even if your requirements are different.</p><h3>Working WITH the Model</h3><p>Knowing these limitations, you can work with them:</p><ol><li>Provide explicit context about your specific requirements</li><li>Use examples (few-shot prompting) to steer patterns</li><li>Verify outputs—never trust blindly</li><li>Break complex tasks into simpler sub-tasks</li></ol><h3>When AI Breaks</h3><p>AI breaks in predictable ways: novel requirements, complex logic, edge cases, security concerns. Knowing WHEN it will fail is half the battle.</p>',
    summary = 'LLMs predict likely outputs based on patterns, not through reasoning. Understanding this helps you work around hallucinations and context limitations.',
    case_studies = '[{"title": "The Hallucinated API", "scenario": "A developer asked Claude to integrate with the Stripe API. It generated code using stripe.createCustomerSession() - a function that does not exist.", "analysis": "The AI pattern-matched Stripe API patterns and invented a plausible-sounding method. The code looked correct but failed at runtime.", "outcome": "The team learned to always verify AI-generated API calls against official documentation. They now paste actual API docs into context."}]'::jsonb,
    key_takeaways = '["AI predicts patterns, it does not reason - adjust expectations accordingly.", "Hallucinations are confident lies - always verify critical code.", "Context is king - the more you provide, the better the output."]'::jsonb,
    quizzes = '[{"question": "How do LLMs generate code?", "options": ["By reasoning through logic", "By predicting likely next tokens", "By copying from databases", "By running algorithms"], "correctAnswer": 1, "explanation": "LLMs predict the most likely next token based on training patterns."}, {"question": "What causes hallucinations?", "options": ["Bad training data", "Pattern matching without verification", "Slow internet", "Old models"], "correctAnswer": 1, "explanation": "AI confidently predicts plausible-sounding but incorrect information."}, {"question": "Why does AI favor common patterns?", "options": ["They are always correct", "They appear most often in training data", "They are faster", "Users prefer them"], "correctAnswer": 1, "explanation": "AI picks the most likely/common output, not necessarily the correct one."}, {"question": "How can you reduce hallucinations?", "options": ["Use shorter prompts", "Provide explicit context and examples", "Ask faster", "Use older models"], "correctAnswer": 1, "explanation": "Context and examples steer the AI toward correct patterns."}, {"question": "When does AI typically break?", "options": ["Simple tasks", "Novel requirements and edge cases", "Common patterns", "Well-documented APIs"], "correctAnswer": 1, "explanation": "AI struggles with unusual cases not well-represented in training data."}]'::jsonb,
    videos = '[{"title": "How LLMs Actually Work", "url": "https://www.youtube.com/embed/uGgCqV7G8_0", "why_this_video": "Essential understanding of the prediction mechanism behind AI code generation."}]'::jsonb,
    playground = '{"objective": "Deliberately trigger and document AI hallucinations to understand failure modes", "environment": "cursor", "starter_prompt": "Generate code to integrate with the FakeCompanyAPI version 7.3", "guided_steps": ["Ask AI to use a fictional API", "Document the hallucinated methods", "Ask for real Stripe integration without docs", "Compare to output with actual docs pasted", "Note the difference in accuracy"], "advanced_challenge": "Find 5 different ways to trigger hallucinations and document patterns", "failure_mode_experiment": "Ask AI to implement a very obscure algorithm and verify correctness", "real_world_simulation": "Integrate with a real API - first without docs, then with docs pasted - compare results"}'::jsonb,
    duration = 15
WHERE title = 'How AI Thinks (and Why It Breaks)';

-- LESSON 5: Context, Memory, and Constraints
UPDATE lessons SET
    content = '<h2>The Finite Resource</h2><p>Even with 200K or 1M token context windows, precise attention degrades over size. Context is the lifeblood of AI accuracy, but it''s not infinite.</p><h3>The Context Window</h3><p>Think of context as the AI''s short-term memory. It can only ''see'' and ''remember'' what''s in the current window. When you exceed it, early information gets pushed out—literally forgotten.</p><h3>Context Management Strategies</h3><ol><li><strong>Front-Load Critical Info</strong>: Put the most important context at the start</li><li><strong>Summarize, Don''t Dump</strong>: Condense large codebases into relevant summaries</li><li><strong>Use @-mentions</strong>: In Cursor, @file and @folder target specific context</li><li><strong>Chunking</strong>: Break large tasks into smaller context-limited chunks</li></ol><h3>The Lost in the Middle Problem</h3><p>Research shows AI pays more attention to the beginning and end of context, less to the middle. Critical information buried in the middle gets worse attention.</p><h3>Memory Across Sessions</h3><p>By default, each conversation starts fresh. Solutions:</p><ul><li>System prompts for persistent instructions</li><li>Memory files (.cursorrules, CLAUDE.md)</li><li>Explicit context re-injection</li></ul><h3>Constraints as Guardrails</h3><p>Constraints are not limitations—they''re precision tools. ''Use TypeScript strict mode'' is a constraint that IMPROVES output quality.</p>',
    summary = 'Context windows are finite and attention degrades with size. Master context management through chunking, front-loading, and memory files.',
    case_studies = '[{"title": "The 50-File Refactor That Failed", "scenario": "A team tried to refactor 50 files at once using Cursor Composer. The AI started strong but output degraded as context filled.", "analysis": "By file 30, the AI was ''forgetting'' patterns established in file 1. Contradictory code was generated.", "outcome": "They switched to batch processing: 5 files at a time with explicit pattern reminders. Success rate went from 60% to 95%."}]'::jsonb,
    key_takeaways = '["Context is finite - manage it strategically.", "Front-load critical information - attention is highest at the start.", "Use memory files for persistent context across sessions."]'::jsonb,
    quizzes = '[{"question": "What happens when context window is exceeded?", "options": ["AI works faster", "Early information is forgotten", "Output improves", "Nothing"], "correctAnswer": 1, "explanation": "When context overflows, early information is pushed out and forgotten."}, {"question": "Where should critical information go?", "options": ["In the middle", "At the end", "At the start (front-loaded)", "Anywhere"], "correctAnswer": 2, "explanation": "Attention is highest at the beginning of context."}, {"question": "What is the Lost in the Middle problem?", "options": ["Files get lost", "Middle context gets less attention", "AI forgets the task", "Slow processing"], "correctAnswer": 1, "explanation": "AI pays less attention to information in the middle of long contexts."}, {"question": "How do you maintain context across sessions?", "options": ["Hope it remembers", "Use memory files like .cursorrules", "Restart often", "Use shorter prompts"], "correctAnswer": 1, "explanation": "Memory files provide persistent context that loads each session."}, {"question": "Constraints in prompts are:", "options": ["Limitations to avoid", "Precision tools that improve output", "Optional extras", "AI blockers"], "correctAnswer": 1, "explanation": "Constraints guide AI toward correct patterns."}]'::jsonb,
    videos = '[{"title": "Context Window Management", "url": "https://www.youtube.com/embed/FdbBgZp33W0", "why_this_video": "Practical strategies for managing context in long coding sessions."}]'::jsonb,
    playground = '{"objective": "Experiment with context limits and observe degradation", "environment": "cursor", "starter_prompt": "Generate 10 React components following this exact pattern: [define pattern]", "guided_steps": ["Define a specific code pattern", "Generate 5 components - note quality", "Generate 10 more without refreshing context", "Observe degradation in later outputs", "Test with explicit reminder at each step"], "advanced_challenge": "Refactor 20 files maintaining consistency throughout", "failure_mode_experiment": "Deliberately overflow context and document where quality breaks down", "real_world_simulation": "Set up .cursorrules for a real project with your coding standards"}'::jsonb,
    duration = 15
WHERE title = 'Context, Memory, and Constraints';

-- LESSON 6: Preventing Repetition & Duplicate Content
UPDATE lessons SET
    content = '<h2>The Loop Problem</h2><p>AI agents often get stuck in loops—repeating the same code, regenerating similar content, or oscillating between solutions. Understanding this failure mode is critical for Vibe Coding mastery.</p><h3>Why AI Loops</h3><ul><li><strong>Pattern Persistence</strong>: Once AI generates a pattern, it reinforces itself</li><li><strong>Lack of Memory</strong>: AI doesn''t remember what it already generated</li><li><strong>Vague Stopping Criteria</strong>: ''Keep improving'' leads to infinite loops</li><li><strong>Conflicting Instructions</strong>: Contradictory requirements cause oscillation</li></ul><h3>Building Exit Conditions</h3><p>Every iterative prompt needs clear exit conditions. ''Do this until X is true'' is powerful. ''Keep doing this'' is dangerous.</p><h3>The Deduplication Mindset</h3><ol><li>Track what has been generated</li><li>Explicitly list what NOT to repeat</li><li>Use unique identifiers when possible</li><li>Verify uniqueness before accepting output</li></ol><h3>Practical Anti-Loop Strategies</h3><ul><li>State machines with defined transitions</li><li>Counters and limits (''Generate exactly 5, no more'')</li><li>Explicit ''done'' conditions</li><li>Human-in-the-loop checkpoints</li></ul><h3>Self-Correcting Systems</h3><p>Design systems that detect their own loops. If the same solution appears twice, trigger a reset or alternative path.</p>',
    summary = 'AI agents get stuck in loops due to pattern persistence and lack of memory. Build explicit exit conditions and deduplication checks.',
    case_studies = '[{"title": "The Infinite Blog Generator", "scenario": "An AI was tasked with generating unique blog posts. After 50 posts, it was recycling the same 10 ideas with minor variations.", "analysis": "Without explicit tracking of previous content, the AI converged on its most ''comfortable'' patterns.", "outcome": "Adding a content hash check and explicit exclusion list reduced duplicates from 80% to 5%."}]'::jsonb,
    key_takeaways = '["Every iteration needs an exit condition.", "Track what has been generated to prevent loops.", "Design self-correcting systems that detect repetition."]'::jsonb,
    quizzes = '[{"question": "Why do AI agents get stuck in loops?", "options": ["They are too fast", "Lack of memory and vague stopping criteria", "They are too smart", "User error only"], "correctAnswer": 1, "explanation": "AI doesn''t remember previous outputs and needs explicit exit conditions."}, {"question": "What is pattern persistence?", "options": ["Good coding habits", "AI reinforcing its own patterns", "Saving files", "Code reuse"], "correctAnswer": 1, "explanation": "Once AI generates a pattern, it tends to repeat it."}, {"question": "How do you prevent infinite loops?", "options": ["Hope it stops", "Add explicit exit conditions", "Use faster AI", "Shorter prompts"], "correctAnswer": 1, "explanation": "Clear exit conditions tell AI when to stop."}, {"question": "What is the deduplication mindset?", "options": ["Delete duplicates after", "Track and prevent duplicates during generation", "Ignore duplicates", "Only generate one thing"], "correctAnswer": 1, "explanation": "Actively tracking what''s generated prevents repetition."}, {"question": "Self-correcting systems should:", "options": ["Ignore errors", "Detect their own loops and reset", "Run forever", "Never change"], "correctAnswer": 1, "explanation": "Systems should detect repetition and trigger alternatives."}]'::jsonb,
    videos = '[{"title": "Building Reliable AI Agents", "url": "https://www.youtube.com/embed/1PHk_g8gWbU", "why_this_video": "Shows how to build AI workflows that don''t get stuck in loops."}]'::jsonb,
    playground = '{"objective": "Build a content generator with anti-loop mechanisms", "environment": "cursor", "starter_prompt": "Generate 10 unique product descriptions, each must be different", "guided_steps": ["Generate content without tracking", "Count duplicates in output", "Add explicit uniqueness requirements", "Implement a tracking mechanism", "Compare duplicate rates"], "advanced_challenge": "Build a generator that self-detects and corrects its own loops", "failure_mode_experiment": "Deliberately create an infinite loop prompt and observe the behavior", "real_world_simulation": "Create a blog post generator that guarantees unique angles"}'::jsonb,
    duration = 15
WHERE title = 'Preventing Repetition & Duplicate Content';

-- LESSON 7: The Vibe Coding Loop
UPDATE lessons SET
    content = '<h2>The Circle of Life</h2><p>Vibe Coding follows a consistent loop: <strong>Define Intent → Scope → Structure → Generate → Verify → Ship → Iterate</strong>. Master this loop and you master AI-assisted development.</p><h3>Step 1: Define Intent</h3><p>What are you trying to build? Not HOW, but WHAT and WHY. ''A subscription management system so users can upgrade/downgrade plans.'' Clear intent guides everything.</p><h3>Step 2: Scope</h3><p>What''s in, what''s out? ''This version: Stripe integration, plan switching. NOT: annual billing, enterprise tiers.'' Scope prevents runaway complexity.</p><h3>Step 3: Structure</h3><p>Break into components. ''1) API endpoint for plan change, 2) Stripe webhook handler, 3) UI for plan selection, 4) Email confirmation.'' Structure creates tractable AI tasks.</p><h3>Step 4: Generate</h3><p>Now prompt the AI. Each component becomes a focused generation task. ''Create a Next.js API route at /api/subscription/change that accepts {newPlan} and calls Stripe...''</p><h3>Step 5: Verify</h3><p>Does it work? Run it. Test edge cases. Check error handling. AI-generated code needs validation—always.</p><h3>Step 6: Ship</h3><p>Deploy what works. Iterate on what doesn''t. ''Ship'' means moving forward, not perfection.</p><h3>Step 7: Iterate</h3><p>Refine based on feedback. The loop continues. Each iteration improves the system.</p>',
    summary = 'The Vibe Coding Loop (Intent → Scope → Structure → Generate → Verify → Ship → Iterate) is the systematic workflow for AI-assisted development.',
    case_studies = '[{"title": "The MVP in a Weekend", "scenario": "A solo founder used the Vibe Coding Loop to build a booking system MVP in 48 hours.", "analysis": "By strictly following the loop - defining intent first, scoping aggressively, structuring into 8 components - each AI generation was focused and successful.", "outcome": "Weekend launch, 100 signups, paying customers within a week. The systematic approach prevented scope creep and AI confusion."}]'::jsonb,
    key_takeaways = '["Intent first - always know WHAT and WHY before HOW.", "Scope aggressively - what is OUT is as important as what is IN.", "Verify always - AI code needs validation before shipping."]'::jsonb,
    quizzes = '[{"question": "What comes FIRST in the Vibe Coding Loop?", "options": ["Generate", "Define Intent", "Ship", "Verify"], "correctAnswer": 1, "explanation": "Intent (WHAT and WHY) must be clear before anything else."}, {"question": "What does Scope define?", "options": ["Code quality", "What is included AND excluded", "Team size", "Timeline"], "correctAnswer": 1, "explanation": "Scope sets boundaries - what''s in AND what''s out."}, {"question": "Why break into Structure?", "options": ["AI can''t handle large tasks", "Creates tractable AI tasks", "Looks organized", "Required by frameworks"], "correctAnswer": 1, "explanation": "Smaller structured tasks produce better AI generation."}, {"question": "What is the purpose of Verify?", "options": ["Make code pretty", "Validate AI-generated code works correctly", "Add comments", "Deploy faster"], "correctAnswer": 1, "explanation": "AI code needs testing - verification catches errors."}, {"question": "What does Ship mean in this context?", "options": ["Perfect code only", "Moving forward with what works", "Final version", "Package for sale"], "correctAnswer": 1, "explanation": "Ship means progress, not perfection - iterate on issues."}]'::jsonb,
    videos = '[{"title": "The Vibe Coding Workflow", "url": "https://www.youtube.com/embed/5EFd0n_n7bU", "why_this_video": "Complete walkthrough of the Intent-to-Ship loop in practice."}]'::jsonb,
    playground = '{"objective": "Practice the complete Vibe Coding Loop on a real mini-project", "environment": "cursor", "starter_prompt": "Build a simple contact form with email sending", "guided_steps": ["Write down Intent: What and Why (2 sentences)", "Define Scope: 3 things IN, 3 things OUT", "Structure: List 4 components needed", "Generate: Prompt for each component separately", "Verify: Test the form end-to-end", "Ship: Deploy or commit", "Iterate: Identify one improvement"], "advanced_challenge": "Complete the full loop twice in one hour for two different features", "failure_mode_experiment": "Skip the Scope step and observe how generation quality suffers", "real_world_simulation": "Apply the loop to an actual feature request from a client or project"}'::jsonb,
    duration = 15
WHERE title = 'The Vibe Coding Loop';

-- Continue with remaining lessons...
SELECT 'Updated lessons 2-7 successfully' as status;
