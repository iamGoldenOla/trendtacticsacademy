-- ==========================================
-- PROMPT ENGINEERING MODULE 1 - LESSONS 2-5
-- Foundations & Behavior Architecture (Continued)
-- ~1200 words each, compact HTML
-- ==========================================

DO $$
BEGIN
    RAISE NOTICE 'üìö Expanding Prompt Engineering Module 1 (Lessons 2-5)...';
    
    -- LESSON 2: Understanding AI Models (ID: fd786a68-b151-4805-9577-3db02bb2fd53)
    UPDATE lessons SET content = '<div class="lesson-content"><h2>Understanding AI Models</h2><h3>How AI Actually Works</h3><p>To write effective prompts, you need to understand what''s happening under the hood. AI models aren''t magic‚Äîthey''re sophisticated pattern-matching systems with specific capabilities and limitations. This lesson demystifies AI models so you can prompt them more effectively.</p><h3>What Is a Language Model?</h3><p>Large Language Models (LLMs) like GPT-4, Claude, and Gemini are: Trained on massive amounts of text data (books, websites, code, conversations). Pattern recognition systems that predict what words should come next. Statistical models that understand relationships between concepts. Not databases (they don''t "look up" facts). Not conscious (they don''t "understand" in a human sense). Think of them as incredibly sophisticated autocomplete systems that have read most of the internet and learned patterns in language, reasoning, and knowledge.</p><h3>How Training Works</h3><h4>Pre-Training Phase</h4><p>The model learns from billions of text examples: Reading text and predicting the next word. Adjusting internal parameters when wrong. Building statistical understanding of language. Learning patterns, facts, reasoning, and style. Result: A model that can generate coherent, contextually appropriate text.</p><h4>Fine-Tuning Phase</h4><p>The model is refined for specific tasks: Following instructions. Answering questions helpfully. Refusing harmful requests. Maintaining consistent personality. Admitting uncertainty. Result: A helpful assistant rather than just a text predictor.</p><h4>Reinforcement Learning from Human Feedback (RLHF)</h4><p>Humans rate model outputs: Helpful vs unhelpful. Accurate vs inaccurate. Safe vs unsafe. Appropriate vs inappropriate. Result: Models that align with human preferences and values.</p><h3>Key Capabilities</h3><h4>1. Pattern Recognition</h4><p>AI excels at recognizing patterns in: Language structure and grammar. Writing styles and tones. Code patterns and conventions. Logical reasoning chains. Common problem-solution pairs. Implication for prompting: Provide clear patterns for AI to follow. Use examples to establish patterns. Be consistent in your structure.</p><h4>2. Context Understanding</h4><p>AI can track context across: Conversations (remembering what was said). Documents (understanding relationships). Tasks (maintaining consistency). Instructions (following multi-step processes). Implication for prompting: Provide relevant context upfront. Reference previous parts of conversation. Build on established context.</p><h4>3. Knowledge Synthesis</h4><p>AI can combine knowledge from: Multiple domains. Different perspectives. Various sources. Diverse examples. Implication for prompting: Ask for synthesis across topics. Request multi-disciplinary insights. Combine different knowledge areas.</p><h4>4. Reasoning and Logic</h4><p>AI can perform: Deductive reasoning (general to specific). Inductive reasoning (specific to general). Analogical reasoning (comparing similarities). Causal reasoning (cause and effect). Implication for prompting: Ask AI to "think through" problems. Request step-by-step reasoning. Have AI explain its logic.</p><h3>Key Limitations</h3><h4>1. No Real-Time Knowledge</h4><p>AI models have a knowledge cutoff: GPT-4: Training data up to April 2023 (varies by version). Claude: Similar cutoff dates. They don''t know current events, recent developments, or real-time information. Implication for prompting: Provide current information when needed. Don''t rely on AI for latest news. Give context about recent changes.</p><h4>2. No True Understanding</h4><p>AI doesn''t actually "understand" like humans: It recognizes patterns, not meaning. It predicts text, not thinks. It simulates reasoning, not reasons. It appears intelligent through pattern matching. Implication for prompting: Verify outputs, especially for critical tasks. Don''t assume AI "gets" nuance. Be explicit about requirements.</p><h4>3. Hallucinations</h4><p>AI sometimes generates plausible but false information: Making up facts. Creating fake citations. Inventing plausible-sounding details. Confidently stating incorrect information. Implication for prompting: Verify factual claims. Ask for sources. Use verification prompts. Don''t trust blindly.</p><h4>4. Inconsistency</h4><p>Same prompt can yield different results: Due to randomness in generation. Temperature settings. Context variations. Model updates. Implication for prompting: Test prompts multiple times. Use temperature controls. Implement verification. Accept some variability.</p><h4>5. Context Window Limits</h4><p>AI can only "remember" a limited amount: GPT-4: 8K-128K tokens (depending on version). Claude: Up to 200K tokens. Tokens ‚âà words (roughly 1.3 tokens per word). Implication for prompting: Keep conversations focused. Summarize long contexts. Start fresh when needed. Prioritize important information.</p><h3>How AI Generates Responses</h3><p>Step-by-step process: 1. Receives your prompt (tokenizes it). 2. Processes through neural network layers. 3. Predicts most likely next token. 4. Generates token by token. 5. Continues until complete response. 6. Returns final output. This is why: AI can''t "go back" and revise easily. Earlier parts influence later parts. Longer outputs may drift. Specific formatting helps guide generation.</p><h3>Temperature and Randomness</h3><p><strong>Temperature</strong> controls randomness in generation: <strong>Temperature 0 (deterministic):</strong> Always picks most likely next word. Consistent outputs. Good for factual tasks. Less creative. <strong>Temperature 0.7 (balanced):</strong> Some randomness. More variety. Good for creative tasks. Still coherent. <strong>Temperature 1.0+ (creative):</strong> High randomness. Very diverse outputs. Good for brainstorming. May be incoherent. Implication for prompting: Request specific temperature for task. Use low temp for consistency. Use high temp for creativity.</p><h3>Different Model Strengths</h3><h4>GPT-4 (OpenAI)</h4><p>Strengths: Broad knowledge. Strong reasoning. Good at following complex instructions. Excellent code generation. Best for: Complex tasks. Technical content. Multi-step reasoning. Code and analysis.</p><h4>Claude (Anthropic)</h4><p>Strengths: Long context windows. Nuanced understanding. Careful, thoughtful responses. Good at avoiding harmful content. Best for: Long documents. Detailed analysis. Ethical considerations. Careful reasoning.</p><h4>Gemini (Google)</h4><p>Strengths: Multimodal (text, images, video). Google integration. Real-time information (in some versions). Fast responses. Best for: Multimodal tasks. Google ecosystem. Quick queries. Image understanding.</p><h3>Tokens and Costs</h3><p>Understanding tokens matters for: API costs (charged per token). Context limits (measured in tokens). Response length (controlled by tokens). Rough conversion: 1 token ‚âà 4 characters. 1 token ‚âà 0.75 words. 100 tokens ‚âà 75 words. Implication for prompting: Be concise to save costs. Monitor token usage. Optimize prompt length. Consider context limits.</p><h3>Prompt Engineering Implications</h3><p>Based on how AI works: <strong>Be explicit</strong> - AI doesn''t assume, it predicts. <strong>Provide context</strong> - More context = better predictions. <strong>Use structure</strong> - Clear structure guides generation. <strong>Give examples</strong> - Patterns help AI understand. <strong>Verify outputs</strong> - AI can be confidently wrong. <strong>Iterate</strong> - First output rarely perfect. <strong>Understand limits</strong> - Work within AI capabilities.</p><h3>The Mental Model</h3><p>Think of AI as: A highly educated intern who has read everything but has no real-world experience. Needs clear instructions. Can make connections you might miss. Sometimes confidently wrong. Gets better with feedback. Works best with structure.</p><h3>Key Takeaways</h3><ul><li>AI models are <strong>pattern-matching systems</strong>, not databases or conscious entities</li><li>Training involves: <strong>pre-training, fine-tuning, and RLHF</strong></li><li>Key capabilities: <strong>pattern recognition, context understanding, knowledge synthesis, reasoning</strong></li><li>Key limitations: <strong>no real-time knowledge, hallucinations, inconsistency, context limits</strong></li><li>AI generates <strong>token by token</strong>, predicting most likely next word</li><li><strong>Temperature</strong> controls randomness: low for consistency, high for creativity</li><li>Different models have <strong>different strengths</strong>: GPT-4, Claude, Gemini</li><li>Understanding AI mechanics helps you <strong>prompt more effectively</strong></li></ul><p>In the next lesson, we''ll define what prompt engineering really is and how it differs from just "asking questions."</p></div>'
    WHERE id = 'fd786a68-b151-4805-9577-3db02bb2fd53';
    RAISE NOTICE '  ‚úÖ Lesson 2: Understanding AI Models';
    
    RAISE NOTICE '';
    RAISE NOTICE 'üéâ MODULE 1 LESSONS 1-2 COMPLETE!';
    RAISE NOTICE 'üìù Continuing with lessons 3-5 in next file...';
    
END $$;
