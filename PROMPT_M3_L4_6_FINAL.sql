-- ==========================================
-- PROMPT ENGINEERING MODULE 3 - LESSONS 4-6 (FINAL - COMPLETE MODULE 3)
-- Advanced Workflows & Meta-Prompting
-- ~1200 words each, compact HTML
-- ==========================================

-- LESSON 4: Prompt Chaining (ID: 725f4c44-2f43-4caa-8f7d-06455a2b54f7)
UPDATE lessons SET content = '<div class="lesson-content"><h2>Prompt Chaining</h2><h3>Multi-Step Workflows</h3><p>Prompt chaining connects multiple prompts in sequence where each prompt builds on previous outputs. This enables complex workflows that single prompts cannot handle. This lesson teaches you how to design and implement effective prompt chains.</p><h3>What Is Prompt Chaining?</h3><p>Prompt chaining is a sequence of prompts where output of one prompt becomes input to the next. Each step performs a specific subtask. Steps are connected in a workflow. Final output is the result of the entire chain. Think of it as an assembly line for AI tasks.</p><h3>Why Chain Prompts?</h3><p>Chaining enables: Breaking complex tasks into manageable steps, specialization at each step, better quality through focused prompts, easier debugging and refinement, reusable workflow components, and handling tasks beyond single-prompt capability.</p><h3>Basic Chain Pattern</h3><p>The simplest chain is linear. Step 1: Process input, produce Output A. Step 2: Take Output A, produce Output B. Step 3: Take Output B, produce final output. Each step has a clear input and output. Example: Research then Write then Edit.</p><h3>Chain Design Principles</h3><p>Principle 1 - Single Responsibility: Each step does one thing well. Principle 2 - Clear Interfaces: Define what each step receives and produces. Principle 3 - Loose Coupling: Steps independent, can be modified separately. Principle 4 - Error Handling: Each step validates its input and output. Principle 5 - Composability: Steps can be reused in different chains.</p><h3>Common Chain Patterns</h3><p>Pattern 1 - Linear Chain: A to B to C to D. Simple sequential processing. Pattern 2 - Branching Chain: A to B, then either C or D based on condition. Conditional logic. Pattern 3 - Parallel Chain: A splits to B and C simultaneously, then merge. Parallel processing. Pattern 4 - Iterative Chain: A to B to C, repeat until condition met. Refinement loops. Pattern 5 - Hierarchical Chain: Main chain with sub-chains. Nested workflows.</p><h3>Designing Effective Chains</h3><p>Start with the end goal. Work backwards to identify steps. Define clear inputs and outputs for each step. Minimize dependencies between steps. Plan for error handling. Document the workflow. Test each step independently. Test the complete chain.</p><h3>Example: Content Creation Chain</h3><p>Step 1 - Research: Input: Topic. Output: Key facts, sources, angles. Step 2 - Outline: Input: Research. Output: Structured outline. Step 3 - Draft: Input: Outline. Output: First draft. Step 4 - Edit: Input: Draft. Output: Polished content. Step 5 - SEO Optimize: Input: Content. Output: Final optimized version. Each step specialized and focused.</p><h3>Example: Data Analysis Chain</h3><p>Step 1 - Data Validation: Check data quality, identify issues. Step 2 - Data Cleaning: Fix issues, standardize format. Step 3 - Exploratory Analysis: Identify patterns and insights. Step 4 - Statistical Analysis: Perform calculations and tests. Step 5 - Visualization: Create charts and graphs. Step 6 - Report Generation: Synthesize into report. Systematic data processing.</p><h3>Information Flow</h3><p>Manage what passes between steps. Full output: Pass everything to next step. Filtered output: Pass only relevant parts. Metadata: Include confidence scores, assumptions. Accumulated context: Build context across chain. Side channels: Additional information alongside main flow. Design information flow carefully.</p><h3>Error Handling in Chains</h3><p>Handle failures gracefully. Strategy 1 - Fail Fast: Stop chain on first error. Strategy 2 - Continue with Warnings: Note error, continue if possible. Strategy 3 - Retry: Attempt failed step again. Strategy 4 - Fallback: Use alternative approach. Strategy 5 - Human Escalation: Request human intervention. Choose strategy based on criticality.</p><h3>Chain Optimization</h3><p>Optimize for performance and cost. Caching: Reuse results of expensive steps. Parallelization: Run independent steps concurrently. Batching: Process multiple items together. Early termination: Stop if goal achieved early. Step skipping: Skip unnecessary steps based on input. Balance speed, cost, and quality.</p><h3>Implementing Chains</h3><p>Implementation approaches. Manual: Run each prompt manually, copy outputs. Scripted: Use code to automate the chain. Workflow tools: Use specialized platforms. API orchestration: Programmatic control via APIs. Choose based on complexity and scale.</p><h3>Chain Validation</h3><p>Validate at each step. Input validation: Check inputs meet requirements. Output validation: Verify outputs are correct. Consistency checks: Ensure logical flow. Quality gates: Meet quality thresholds. Final validation: Complete chain produces desired result. Catch errors early.</p><h3>Iterative Refinement Chains</h3><p>Chains that loop until quality threshold met. Generate initial output. Evaluate quality. If not good enough, refine and repeat. Continue until satisfactory or max iterations. Example: Draft, Critique, Revise loop. Improves quality through iteration.</p><h3>Conditional Branching</h3><p>Chains that adapt based on intermediate results. If condition A: Take path 1. Else if condition B: Take path 2. Else: Take default path. Example: If sentiment negative, route to complaint handling. If positive, route to upsell. Adaptive workflows.</p><h3>Common Chain Mistakes</h3><p>Mistake 1: Too many steps (overcomplicated). Solution: Combine related steps. Mistake 2: Steps too dependent (tight coupling). Solution: Design for independence. Mistake 3: No validation (errors propagate). Solution: Validate at each step. Mistake 4: Information loss (context dropped). Solution: Preserve necessary context.</p><h3>Chain Documentation</h3><p>Document your chains. Chain purpose and goals. Step-by-step description. Input and output for each step. Error handling procedures. Performance characteristics. Example inputs and outputs. Maintenance notes. Enables reuse and improvement.</p><h3>Key Takeaways</h3><ul><li>Prompt chaining connects multiple prompts in sequence</li><li>Enables complex workflows beyond single-prompt capability</li><li>Each step has single responsibility and clear interface</li><li>Common patterns: linear, branching, parallel, iterative, hierarchical</li><li>Design information flow carefully between steps</li><li>Implement error handling and validation</li><li>Optimize for performance and cost</li><li>Document chains for reuse and maintenance</li></ul><p>In the next lesson, we will explore Iterative Refinement techniques.</p></div>'
WHERE id = '725f4c44-2f43-4caa-8f7d-06455a2b54f7';

-- LESSON 5: Iterative Refinement and Prompt Chaining (ID: ea2bda0e-356e-46d6-934a-d150c10a3ff7)
UPDATE lessons SET content = '<div class="lesson-content"><h2>Iterative Refinement and Prompt Chaining</h2><h3>Continuous Improvement Workflows</h3><p>Iterative refinement uses cycles of generation, evaluation, and improvement to achieve high-quality outputs. Combined with prompt chaining, it creates powerful self-improving workflows. This lesson teaches you how to implement iterative refinement effectively.</p><h3>What Is Iterative Refinement?</h3><p>Iterative refinement is a process of continuous improvement. Generate initial output. Evaluate against criteria. Identify improvements needed. Refine and regenerate. Repeat until satisfactory. Each iteration improves quality.</p><h3>Why Iterate?</h3><p>Iteration provides: Higher quality outputs, ability to meet complex requirements, self-correction of errors, progressive refinement toward goal, and handling of ambiguous requirements. First attempt rarely perfect, iteration bridges the gap.</p><h3>The Refinement Loop</h3><p>Standard refinement pattern. Step 1 - Generate: Create initial output. Step 2 - Evaluate: Assess quality and completeness. Step 3 - Critique: Identify specific issues and improvements. Step 4 - Refine: Apply improvements. Step 5 - Repeat: Continue until criteria met or max iterations reached. Systematic improvement process.</p><h3>Evaluation Criteria</h3><p>Define clear success criteria. Accuracy: Factually correct. Completeness: All requirements addressed. Quality: Well-written and polished. Relevance: On-topic and focused. Format: Meets structural requirements. Constraints: Respects all rules. Measurable criteria enable objective evaluation.</p><h3>Critique Strategies</h3><p>Different ways to critique outputs. Self-critique: AI evaluates its own output. Peer critique: Different AI agent reviews. Criteria-based: Check against specific requirements. Comparative: Compare to examples or standards. Human feedback: Incorporate user input. Choose strategy based on needs.</p><h3>Refinement Prompts</h3><p>How to prompt for refinement. Direct: Here is the output. Improve it by addressing these issues. Specific: The output lacks X. Add it while maintaining Y. Incremental: Make this one specific improvement. Comprehensive: Review and improve all aspects. Guided: Follow these steps to refine. Clear guidance produces better refinements.</p><h3>Convergence Criteria</h3><p>When to stop iterating. Quality threshold: Meets minimum quality score. Diminishing returns: Improvements become minimal. Max iterations: Prevent infinite loops. Time/cost limits: Resource constraints. Human approval: User satisfied. Define stopping conditions upfront.</p><h3>Example: Document Refinement</h3><p>Iteration 1: Generate initial draft. Critique: Missing examples, too technical. Iteration 2: Add examples, simplify language. Critique: Good but needs better structure. Iteration 3: Reorganize with clear sections. Critique: Excellent, minor polish needed. Iteration 4: Final polish. Result: High-quality document. Progressive improvement through iterations.</p><h3>Example: Code Generation</h3><p>Iteration 1: Generate initial code. Evaluate: Works but inefficient. Iteration 2: Optimize performance. Evaluate: Faster but hard to read. Iteration 3: Add comments and improve readability. Evaluate: Good but missing error handling. Iteration 4: Add error handling. Result: Production-ready code. Each iteration addresses specific issues.</p><h3>Combining with Prompt Chaining</h3><p>Powerful combination. Chain Step 1: Generate initial output. Chain Step 2: Critique the output. Chain Step 3: Refine based on critique. Chain Step 4: Validate refinement. Repeat chain until satisfactory. Automated refinement workflow.</p><h3>Multi-Aspect Refinement</h3><p>Refine different aspects separately. Iteration 1: Focus on accuracy. Iteration 2: Focus on completeness. Iteration 3: Focus on style. Iteration 4: Focus on format. Iteration 5: Overall polish. Systematic improvement of each aspect.</p><h3>Feedback Integration</h3><p>Incorporate feedback into refinement. Collect feedback from users or reviewers. Categorize feedback by type. Prioritize feedback by importance. Apply feedback systematically. Verify improvements. Learn from feedback patterns.</p><h3>Refinement Optimization</h3><p>Make refinement efficient. Targeted refinement: Fix specific issues only. Batch refinement: Address multiple issues together. Incremental refinement: Small improvements each iteration. Parallel refinement: Multiple refinement paths, choose best. Smart iteration: Stop when good enough. Balance quality and efficiency.</p><h3>Common Refinement Mistakes</h3><p>Mistake 1: Vague critique (not specific enough). Solution: Identify concrete improvements. Mistake 2: Too many iterations (diminishing returns). Solution: Set clear stopping criteria. Mistake 3: Losing good parts (refinement makes things worse). Solution: Preserve what works well. Mistake 4: No progress tracking (repeating same issues). Solution: Track what has been addressed.</p><h3>Measuring Refinement Effectiveness</h3><p>Track refinement performance. Quality improvement per iteration. Number of iterations needed. Cost per refinement cycle. Success rate (meeting criteria). Time to completion. Optimize based on metrics.</p><h3>Advanced Refinement Techniques</h3><p>Technique 1 - Multi-Path Refinement: Generate multiple refinements, choose best. Technique 2 - Hierarchical Refinement: Refine structure first, then details. Technique 3 - Collaborative Refinement: Multiple agents refine together. Technique 4 - Adaptive Refinement: Adjust strategy based on progress. Technique 5 - Meta-Refinement: Refine the refinement process itself.</p><h3>Key Takeaways</h3><ul><li>Iterative refinement uses cycles of generation, evaluation, and improvement</li><li>Standard loop: generate, evaluate, critique, refine, repeat</li><li>Define clear evaluation criteria and convergence conditions</li><li>Combine with prompt chaining for automated workflows</li><li>Refine different aspects systematically</li><li>Integrate feedback for continuous improvement</li><li>Optimize for efficiency while maintaining quality</li><li>Track metrics to measure effectiveness</li></ul><p>In the next lesson, we will explore Few-Shot Learning and Examples in more depth.</p></div>'
WHERE id = 'ea2bda0e-356e-46d6-934a-d150c10a3ff7';

-- LESSON 6: Few-Shot Learning and Examples (ID: b86a0941-2155-4204-a8fa-a654954888c8)
UPDATE lessons SET content = '<div class="lesson-content"><h2>Few-Shot Learning and Examples</h2><h3>Advanced Example Strategies</h3><p>This lesson builds on basic few-shot learning with advanced strategies for selecting, creating, and using examples to maximize AI performance. You will learn sophisticated techniques for example-based prompting.</p><h3>Beyond Basic Few-Shot</h3><p>Basic few-shot provides a few examples. Advanced few-shot optimizes: Example selection (which examples to use), example ordering (sequence matters), example diversity (coverage of patterns), example quality (clarity and relevance), dynamic examples (adapt to input). Strategic use of examples dramatically improves results.</p><h3>Example Selection Strategies</h3><p>How to choose the best examples. Strategy 1 - Similarity-Based: Select examples most similar to current input. Pro: Highly relevant. Con: May miss edge cases. Strategy 2 - Diversity-Based: Select diverse examples covering range. Pro: Shows full pattern. Con: May include irrelevant examples. Strategy 3 - Difficulty-Based: Include challenging examples. Pro: Handles edge cases. Con: May confuse on simple tasks. Strategy 4 - Performance-Based: Use examples that worked well before. Pro: Proven effectiveness. Con: May not generalize. Strategy 5 - Hybrid: Combine multiple strategies. Pro: Balanced approach. Con: More complex.</p><h3>Example Ordering</h3><p>Order matters in few-shot learning. Ordering strategies: Simple to complex (build understanding progressively), common to rare (establish pattern then show variations), chronological (if time matters), random (avoid bias), strategic (most important first). Test different orderings to find what works best.</p><h3>Example Diversity</h3><p>Cover the pattern space effectively. Diversity dimensions: Input variety (different types of inputs), output variety (different valid outputs), edge cases (boundary conditions), common cases (typical scenarios), error cases (what not to do). Balanced diversity improves generalization.</p><h3>Contrastive Examples</h3><p>Show both good and bad examples. Good examples: This is correct, follow this pattern. Bad examples: This is incorrect, avoid this. Contrastive learning: Highlight differences between good and bad. Clarifies boundaries and requirements. Example: Correct format vs incorrect format side by side.</p><h3>Progressive Examples</h3><p>Build complexity gradually. Example 1: Simple case, basic pattern. Example 2: Add one complexity. Example 3: Add another complexity. Example 4: Full complexity. Helps AI understand pattern progression. Good for complex tasks.</p><h3>Meta-Examples</h3><p>Examples about how to create examples. Show: How to structure examples, what makes a good example, how to vary examples appropriately. Meta-learning: AI learns the pattern of learning. Advanced technique for sophisticated tasks.</p><h3>Dynamic Example Selection</h3><p>Choose examples at runtime. Process: Analyze current input. Find similar examples from library. Select best matches. Include in prompt. Personalized few-shot learning. Requires example database and selection logic.</p><h3>Example Libraries</h3><p>Build reusable example collections. Organize by: Task type, difficulty level, domain, quality, performance. Tag examples with metadata. Version control examples. Curate and refine over time. Share across team. Systematic example management.</p><h3>Example Quality</h3><p>High-quality examples are: Clear and unambiguous, realistic and practical, correctly formatted, well-explained if needed, representative of pattern. Low-quality examples: Confusing or ambiguous, unrealistic or contrived, poorly formatted, missing key elements, not representative. Quality over quantity always.</p><h3>Synthetic Examples</h3><p>Generate examples programmatically. Use AI to create examples. Vary parameters systematically. Cover edge cases comprehensively. Scale example creation. Validate synthetic examples carefully. Useful for rare scenarios.</p><h3>Example Explanation</h3><p>Add explanations to examples. Annotate: Why this example is good, key features to notice, what pattern it demonstrates, how it meets requirements. Helps AI understand not just what but why. Particularly useful for complex patterns.</p><h3>Cross-Domain Examples</h3><p>Use examples from related domains. Analogical reasoning: Apply patterns from one domain to another. Transfer learning: Leverage knowledge across domains. Requires clear mapping between domains. Expands example availability.</p><h3>Example Compression</h3><p>Fit more examples in context window. Techniques: Remove redundant information, use shorthand notation, compress format, focus on key differences. Balance compression with clarity. Useful when context limited.</p><h3>A/B Testing Examples</h3><p>Test different example sets. Compare: Different selection strategies, different orderings, different numbers of examples, different example types. Measure: Output quality, consistency, task success rate. Optimize based on data. Continuous improvement.</p><h3>Common Example Mistakes</h3><p>Mistake 1: Too similar examples (do not show range). Solution: Increase diversity. Mistake 2: Too many examples (waste context). Solution: Find optimal number. Mistake 3: Poor quality examples (confuse AI). Solution: Curate carefully. Mistake 4: Static examples (not adapting). Solution: Implement dynamic selection.</p><h3>Key Takeaways</h3><ul><li>Advanced few-shot optimizes example selection, ordering, and diversity</li><li>Selection strategies: similarity-based, diversity-based, performance-based, hybrid</li><li>Example ordering affects learning - test different sequences</li><li>Use contrastive examples to clarify boundaries</li><li>Build and maintain example libraries</li><li>Quality matters more than quantity</li><li>Dynamic selection adapts examples to input</li><li>A/B test example sets to optimize</li></ul><p>Congratulations! You have completed Module 3. You now understand advanced workflows and meta-prompting. In Module 4, we will explore professional mastery and ethics.</p></div>'
WHERE id = 'b86a0941-2155-4204-a8fa-a654954888c8';

-- MODULE 3 COMPLETE! All 6 lessons expanded!
-- Progress: 17/27 lessons complete (63%)
-- Next: Run PROMPT_M4_COMPLETE.sql for Module 4 (6 lessons)
